\begin{landscape}
	\thispagestyle{empty}
	\begin{center}
		\Huge{\textbf{Sources of Images}} \\
		\normalsize{\textit{for Copyright purposes}}
	\end{center}
	Figure 1.1 from \url{https://blog.dataiku.com/nlp-metamorphosis} \\
	Figure 1.2 from \url{www.dmice.ohsu.edu/hersh/ohsu-pathology-20.pdf} \\
	Figure 1.3 from \url{https://w.wiki/3sAW} \\
	Figure 1.4 from \url{www.researchgate.net/publication/336092695_Densely_Connected_Convolutional_Networks_With_Attention_LSTM} \\
   Figure 1.5 from \href{https://www.medium.com/huggingface/encoder-decoders-in-transformers-a-hybrid-pre-trained-architecture-for-seq2seqaf4d7bf14bb8}{Medium article  transformers}\\
	Figure 1.6 from \href{https://medium.com/@anishnama20/exploring-the-power-of-encoder-decoder-models-pros-cons-and-applications-8bfbe2e66e76}{Medium article on encoder-decoders }	\\
	Figure 1.7 from \url{arxiv.org/abs/2307.09288} \\
	Figure 2.1 from \url{https://arxiv.org/abs/2312.10997} \\
	Figure 2.2 from \href{https://www.researchgate.net/figure/High-level-overview-of-a-possible-solution-using-RAG-and-a-multi-modal-in-context_fig1_380540048}{RAG } \\
   Figure 3.1 from \url{https://ai.gopubby.com/advanced-rag-techniques-unlocking-the-next-level-040c205b95bc} \\
	Figure 3.2 from \url{www.evidentlyai.com/ranking-metrics/precision-recall-at-k} \\
	Figure 3.3 from \url{www.evidentlyai.com/ranking-metrics/precision-recall-at-k} \\
	Figure 3.4 from \url{openreview.net/forum?id=eHF4pDRWjT} \\
	Figure 3.6 from \url{d2l.ai/chapter_recommender-systems/recsys-intro.html} \\
	Figure 3.7 from \url{arxiv.org/abs/1808.09781} \\
\end{landscape}
