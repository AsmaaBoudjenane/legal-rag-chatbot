\babel@toc {english}{}\relax 
\contentsline {chapter}{List of Figures}{}{chapter*.4}%
\contentsline {chapter}{List of Tables}{}{chapter*.5}%
\contentsline {chapter}{List of Abbreviations }{}{chapter*.6}%
\contentsline {chapter}{General introduction}{1}{chapter*.7}%
\contentsline {chapter}{\numberline {1}Large Language Models (LLMs) In Agentic AI }{4}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introduction}{4}{section.1.1}%
\contentsline {section}{\numberline {1.2}Language Models}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Definition of Language Models}{4}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}N-gram Language Models}{5}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Neural Language Models}{6}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Definition of Neural Language Models}{6}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Word Representations (Embedding)}{7}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Continuous Bag-of-Words (CBOW)}{7}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Continuous Skip-gram}{8}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}Global Vectors for Word Representation(GloVe)}{8}{subsection.1.3.5}%
\contentsline {section}{\numberline {1.4}Large Language Models (LLMs)}{9}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Definition of LLMs}{9}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Historical Development of LLMs}{10}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Transformer Architecture}{10}{subsection.1.4.3}%
\contentsline {subsubsection}{\numberline {1.4.3.1}Encoder and Decoder Stacks}{11}{subsubsection.1.4.3.1}%
\contentsline {subsubsection}{\numberline {1.4.3.2}Self-Attention Mechanism in Transformers}{12}{subsubsection.1.4.3.2}%
\contentsline {subsubsection}{\numberline {1.4.3.3}Positional Encoding:}{13}{subsubsection.1.4.3.3}%
\contentsline {subsubsection}{\numberline {1.4.3.4}Role of Multi-Head Attention}{13}{subsubsection.1.4.3.4}%
\contentsline {subsection}{\numberline {1.4.4}Key Contributions of Transformer in Modern NLP}{13}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}Classification of LLMs}{14}{subsection.1.4.5}%
\contentsline {subsection}{\numberline {1.4.6}Training Large Language Models}{16}{subsection.1.4.6}%
\contentsline {subsection}{\numberline {1.4.7}Training Objectives and Loss Functions}{16}{subsection.1.4.7}%
\contentsline {subsection}{\numberline {1.4.8}Parameter Scaling and Model Size}{16}{subsection.1.4.8}%
\contentsline {subsection}{\numberline {1.4.9}Training Paradigms: Pre-training and Fine-tuning}{17}{subsection.1.4.9}%
\contentsline {subsection}{\numberline {1.4.10}Few-Shot, One-Shot, and Zero-Shot Learning}{19}{subsection.1.4.10}%
\contentsline {subsection}{\numberline {1.4.11}Evaluation Datasets}{19}{subsection.1.4.11}%
\contentsline {subsection}{\numberline {1.4.12}Popular Models}{20}{subsection.1.4.12}%
\contentsline {subsubsection}{\numberline {1.4.12.1}GPT-N Models}{20}{subsubsection.1.4.12.1}%
\contentsline {subsubsection}{\numberline {1.4.12.2}Bidirectional Encoder Representations from Transformers (BERT)}{21}{subsubsection.1.4.12.2}%
\contentsline {subsubsection}{\numberline {1.4.12.3}Text-To-Text Transfer Transformer (T5)}{21}{subsubsection.1.4.12.3}%
\contentsline {subsubsection}{\numberline {1.4.12.4}LLAMA2 model}{21}{subsubsection.1.4.12.4}%
\contentsline {subsubsection}{\numberline {1.4.12.5}Jais and Jais-chat models}{22}{subsubsection.1.4.12.5}%
\contentsline {subsection}{\numberline {1.4.13}Limitations of LLMs}{22}{subsection.1.4.13}%
\contentsline {subsection}{\numberline {1.4.14}State of the Art in Juridical Data}{23}{subsection.1.4.14}%
\contentsline {section}{\numberline {1.5}Agentic AI}{23}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Definition of Agentic AI}{24}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Architecture Overview of Agentic AI}{24}{subsection.1.5.2}%
\contentsline {subsection}{\numberline {1.5.3}Types of Agentic AI}{25}{subsection.1.5.3}%
\contentsline {subsection}{\numberline {1.5.4} Agent Categories}{27}{subsection.1.5.4}%
\contentsline {subsection}{\numberline {1.5.5}Key Challenges in Agentic AI}{27}{subsection.1.5.5}%
\contentsline {section}{\numberline {1.6}Conclusion}{28}{section.1.6}%
\contentsline {chapter}{\numberline {2}Retrieval-Augmented Generation in Recommendation System}{29}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction}{29}{section.2.1}%
\contentsline {section}{\numberline {2.2}Retrieval-Augmented Generation (RAG)}{29}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Definition of RAG}{30}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Historical Development of RAG}{30}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Comparison with Fine-Tuning and Transfer Learning}{30}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Retrieval Mechanism}{31}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Generation Process}{32}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Augmentation Techniques}{32}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}Types of RAG Systems}{33}{subsection.2.2.7}%
\contentsline {subsection}{\numberline {2.2.8}Naive RAG}{33}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}Advanced RAG}{34}{subsection.2.2.9}%
\contentsline {subsection}{\numberline {2.2.10}Modular RAG}{35}{subsection.2.2.10}%
\contentsline {subsection}{\numberline {2.2.11}Agentic RAG}{36}{subsection.2.2.11}%
\contentsline {subsection}{\numberline {2.2.12}Evaluation Methods}{37}{subsection.2.2.12}%
\contentsline {subsection}{\numberline {2.2.13}Challenges and Limitations}{38}{subsection.2.2.13}%
\contentsline {subsection}{\numberline {2.2.14}State of the Art in Juridical Data}{39}{subsection.2.2.14}%
\contentsline {section}{\numberline {2.3}Recommendation Systems}{40}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Definition of Recommendation Systems}{40}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Types of Recommendation Systems}{41}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Evaluation Metrics}{42}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Retrieval-Augmented Generation in Recommendation Systems}{43}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Conclusion}{43}{section.2.4}%
\contentsline {chapter}{\numberline {3}k-Selection Optimization in RAG }{44}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{44}{section.3.1}%
\contentsline {section}{\numberline {3.2}Defining k: The Number of Retrieved Documents}{44}{section.3.2}%
\contentsline {section}{\numberline {3.3}Impact of k on Retrieval Performance}{44}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Recall vs. Precision}{45}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Retrieval Speed and Computational Cost}{46}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Document Ranking Quality}{47}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}Impact of k on Generation Quality}{48}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Trade-off Between Diversity and Relevance}{48}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Effect on Text Generation Models}{48}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Existing Solutions for k Selection}{49}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Static k Selection}{49}{subsection.3.5.1}%
\contentsline {subsubsection}{\numberline {3.5.1.1}Sparse Retrieval with Fixed k}{49}{subsubsection.3.5.1.1}%
\contentsline {subsubsection}{\numberline {3.5.1.2}Dense Retrieval with Fixed k}{50}{subsubsection.3.5.1.2}%
\contentsline {subsection}{\numberline {3.5.2}Dynamic k Selection}{50}{subsection.3.5.2}%
\contentsline {subsubsection}{\numberline {3.5.2.1}Dynamic Trade-Off Prediction in Multi-Stage Retrieval Systems }{50}{subsubsection.3.5.2.1}%
\contentsline {subsubsection}{\numberline {3.5.2.2}Dynamic Pruning Methods:}{50}{subsubsection.3.5.2.2}%
\contentsline {subsection}{\numberline {3.5.3}Hybrid k Selection}{50}{subsection.3.5.3}%
\contentsline {subsubsection}{\numberline {3.5.3.1}Blended RAG}{51}{subsubsection.3.5.3.1}%
\contentsline {subsubsection}{\numberline {3.5.3.2} STAYKATE (Static-Dynamic Hybrid Selection)}{51}{subsubsection.3.5.3.2}%
\contentsline {section}{\numberline {3.6}Proposed Solution}{51}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Mixture of Logits (MoL)}{52}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Algorithm Design}{53}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Hybrid k-Selection Algorithm Pseudocode}{54}{subsection.3.6.3}%
\contentsline {section}{\numberline {3.7}Experimental Results}{56}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}Dataset Design}{56}{subsection.3.7.1}%
\contentsline {subsection}{\numberline {3.7.2}Experimental Setup }{56}{subsection.3.7.2}%
\contentsline {subsubsection}{\numberline {3.7.2.1}Fixed Experimental Configuration}{57}{subsubsection.3.7.2.1}%
\contentsline {subsection}{\numberline {3.7.3}Architectural Variants and Results}{57}{subsection.3.7.3}%
\contentsline {subsection}{\numberline {3.7.4}Impact of Adaptive k-Variations on Model Performance}{58}{subsection.3.7.4}%
\contentsline {section}{\numberline {3.8}Conclusion}{60}{section.3.8}%
\contentsline {chapter}{\numberline {4}Design of Arabic RAG-Based Agent for Legal and Juridical Data.}{61}{chapter.4}%
\contentsline {section}{\numberline {4.1}Introduction}{61}{section.4.1}%
\contentsline {section}{\numberline {4.2}Dataset Design}{61}{section.4.2}%
\contentsline {section}{\numberline {4.3}Agent Architecture Overview}{63}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Input/Output}{63}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Preprocessing and Ingestion Phase}{64}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}Retriever Sub-Agent }{64}{subsection.4.3.3}%
\contentsline {subsection}{\numberline {4.3.4}Recommendation Sub-Agent}{65}{subsection.4.3.4}%
\contentsline {subsection}{\numberline {4.3.5}Context Selector: Token-Aware Filtering}{65}{subsection.4.3.5}%
\contentsline {subsection}{\numberline {4.3.6}Functions and Tools}{65}{subsection.4.3.6}%
\contentsline {subsection}{\numberline {4.3.7}Generator: Answer Formulation Component}{65}{subsection.4.3.7}%
\contentsline {subsection}{\numberline {4.3.8}Agent Design}{65}{subsection.4.3.8}%
\contentsline {section}{\numberline {4.4}Training the Agent}{66}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Training the Retriever}{66}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Training the Generator}{68}{subsection.4.4.2}%
\contentsline {section}{\numberline {4.5}Experimental Results}{70}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Training Results}{70}{subsection.4.5.1}%
\contentsline {subsubsection}{\numberline {4.5.1.1}Model Architecture}{70}{subsubsection.4.5.1.1}%
\contentsline {subsubsection}{\numberline {4.5.1.2}Training Configuration}{70}{subsubsection.4.5.1.2}%
\contentsline {subsubsection}{\numberline {4.5.1.3}Inference Settings}{70}{subsubsection.4.5.1.3}%
\contentsline {subsubsection}{\numberline {4.5.1.4}Training Progress :}{71}{subsubsection.4.5.1.4}%
\contentsline {subsection}{\numberline {4.5.2}Evaluation Results}{73}{subsection.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}Retriever Evaluation Results}{73}{subsection.4.5.3}%
\contentsline {paragraph}{Human Evaluation:}{74}{section*.50}%
\contentsline {subsection}{\numberline {4.5.4}Geerator Evaluation Results }{74}{subsection.4.5.4}%
\contentsline {paragraph}{Results:}{74}{section*.52}%
\contentsline {paragraph}{Human Evaluation:}{74}{section*.53}%
\contentsline {section}{\numberline {4.6}Agent Results}{75}{section.4.6}%
\contentsline {section}{\numberline {4.7}Conclusion}{78}{section.4.7}%
\contentsline {chapter}{Bibliography}{80}{chapter*.58}%
